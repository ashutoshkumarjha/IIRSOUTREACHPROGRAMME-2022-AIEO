{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f55223d",
   "metadata": {},
   "source": [
    "# CNN model Using python\n",
    "This note book demostrates the usage of basic python usage to create a CNN network for Geospatial data analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85fbb44",
   "metadata": {},
   "source": [
    "# Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052b6da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from osgeo import gdal\n",
    "import geopandas as gdp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import ensemble, model_selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ff5d94",
   "metadata": {},
   "source": [
    "## Data info \n",
    "Following data are used in this exersize\n",
    "- Raste Data : Landsat 8 data \n",
    "    We are using the stack images given in the folder data/LC08_L1TP_146039_20211229_20220106_01_T1\n",
    "    -- LC08_L1TP_146039_20211229_20220106_01_T1_stack.tif \n",
    "        has 12 bands in the order (B1,B2,B3,B4,B5,B6,B7,B9,B10,B11,BQA). We will use the seven bands from B1-7 in this exersise.\n",
    "- Vector data : 100 Sample points generate using the QGIS. \n",
    "   It contains the attributes \n",
    "   -- rand_point : Id of the random point generated\n",
    "   -- Class : Integer represeting the classes (1:Snow/Clouds, 2:Waste Land , 3:Forest , 4: , 5: )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1041c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path=\"./data/LC08_L1TP_146039_20211229_20220106_01_T1/LC08_L1TP_146039_20211229_20220106_01_T1_stack.tif\"\n",
    "point_path='./data/ClassPoints/rPoints/rPoints.shp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b437d28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds=gdal.Open(img_path)\n",
    "trans=ds.GetGeoTransform()\n",
    "data=ds.ReadAsArray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2baf984c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e45f9fa",
   "metadata": {},
   "source": [
    "## Do the subsetting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d116385",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data[0:7,:,:]\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7792ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape\n",
    "plt.imshow(data[1]) #plot the sencon basdn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a45f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(data[:,5000,2000]) #Check the seven bands details at location 5000,2000\n",
    "trans=ds.GetGeoTransform()\n",
    "Xloc = trans[1] * 5000 + trans[2] * 2000 + trans[0];\n",
    "Yloc = trans[4] * 5000 + trans[5] * 2000 + trans[3];\n",
    "ax.set_xticks([0, 1, 2 ,3 , 4 , 5 ,6])\n",
    "labels=ax.set_xticklabels(['B1', 'B2', 'B3', 'B4', 'B5', 'B6','B7'])\n",
    "ax.set_title(f\"DN value at location ({Xloc} , {Yloc})\")\n",
    "ax.set_xlabel(\"Band No\")\n",
    "ax.set_ylabel(\"Band DN Value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5fb670f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=gdp.read_file(point_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1418ad0",
   "metadata": {},
   "source": [
    "To get the sample value of points at location(lat,long) we need to use the following formula\n",
    "- point.lon-raster.orgin.lon)/pixelsize\n",
    "- point.lat-raster.orgin.lat)/pixelsize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a045e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b509119",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetVal(X): #The function implements the above formual\n",
    "    lon=X.geometry.x\n",
    "    lat=X.geometry.y\n",
    "    r=int((trans[3]-lat)/trans[1])\n",
    "    c=int((trans[0]-lon)/trans[5])\n",
    "    return data[k,r,c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a8351c",
   "metadata": {},
   "outputs": [],
   "source": [
    "noOfBands,_,_=data.shape #Get the number of bands in the data sets\n",
    "print(noOfBands)\n",
    "for k in range(0,noOfBands): #Get the bands values at sample location\n",
    "    df[\"b\"+str(k+1)]=df.apply(GetVal,axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f619b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(3) #Print the details of data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ed54bf",
   "metadata": {},
   "source": [
    "## Prepare the feautures and target \n",
    "For random Forest classfication from the sample points features and targets are created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d01bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature=df[['b1','b2','b3','b4','b5','b6','b7']].values #For sample point locatin  a feature vector contains the \n",
    "#informaion of only bands DN values\n",
    "target=df['Class'].values #The class target label is subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b259c848",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38531356",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e780ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "target.shape #Confirm there are 100 sampel points\n",
    "dataset=df[['b1','b2','b3','b4','b5','b6','b7','Class']]\n",
    "dataset=dataset.to_numpy()\n",
    "dataset.shape\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df86779c",
   "metadata": {},
   "source": [
    "## Setup back Neural Network\n",
    "We will do the following tasks to create a Neural network based Classification\n",
    "- Initialise network\n",
    "- Forward Propagate Computation\n",
    "- Back Propagate Error Computation\n",
    "- Train the Network\n",
    "- Predict a subset area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd3a242",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import seed\n",
    "from random import random\n",
    "from math import exp\n",
    "# Initialize a network\n",
    "def initialize_network(n_inputs, n_hidden, n_outputs):\n",
    "\tnetwork = list()\n",
    "\thidden_layer = [{'weights':[random() for i in range(n_inputs + 1)]} for i in range(n_hidden)]\n",
    "\tnetwork.append(hidden_layer)\n",
    "\toutput_layer = [{'weights':[random() for i in range(n_hidden + 1)]} for i in range(n_outputs)]\n",
    "\tnetwork.append(output_layer)\n",
    "\treturn network\n",
    "\n",
    "seed(1)\n",
    "network = initialize_network(2, 1, 2)\n",
    "for layer in network:\n",
    "\tprint(layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74673264",
   "metadata": {},
   "source": [
    "# Forward Propagate\n",
    "It generates the output from a neural network by propagating an input through layer.\n",
    "It requires the three steps.\n",
    "- Neuron Activation.\n",
    "- Neuron Transfer.\n",
    "- Forward Propagation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4aa07f3",
   "metadata": {},
   "source": [
    "## Neuron Activation.\n",
    "Neuron activation is calculated as the weighted sum of the inputs similar to regression sum.\n",
    "\n",
    "$z^{(l)}= weightedSum = \\sum(weight^{(l)} * x^{(l)}) + bias^{(l)}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35dbb553",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate neuron activation for an input\n",
    "def activate(weights, inputs):\n",
    "\tweightedSum = weights[-1]\n",
    "\tfor l in range(len(weights)-1):\n",
    "\t\tweightedSum += weights[l] * inputs[l]+weights[-1]\n",
    "\treturn weightedSum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5c428f",
   "metadata": {},
   "source": [
    "## Neuron Transfer\n",
    "We can use different activation functions to transform the neuron activation. This includes \n",
    "1. $a^{(l)}(x)=\\frac{1}{(1+e^{-ð‘§^{(l)}(x)})}$    [Sigmoid](https://en.wikipedia.org/wiki/Sigmoid_function)\n",
    "2. $a^{(l)}(x)=max(0,ð‘§^{(l)}(x))$  [Relu](https://en.wikipedia.org/wiki/Rectifier_(neural_networks))\n",
    "Here we are using the Sigmoid function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b536b211",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def transfer(weightedSum):\n",
    "\treturn 1.0 / (1.0 + exp(-weightedSum))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "642c5e36",
   "metadata": {},
   "source": [
    "# Forward Propagation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1907b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagate(network, row):\n",
    "\tinputs = row\n",
    "\tfor layer in network:\n",
    "\t\tnew_inputs = []\n",
    "\t\tfor neuron in layer:\n",
    "\t\t\tactivation = activate(neuron['weights'], inputs)\n",
    "\t\t\tneuron['output'] = transfer(activation)\n",
    "\t\t\tnew_inputs.append(neuron['output'])\n",
    "\t\tinputs = new_inputs\n",
    "\treturn inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "698d32f5",
   "metadata": {},
   "source": [
    "## Back Propagate Error\n",
    "1. Transfer Derivative.\n",
    "- $a'^{(l)}=\\frac{d}{dz}z^{(l)}=z^{(l)}(1-z^{(l)})$\n",
    "2. Error Backpropagation.\n",
    "- $\\frac{\\partial E}{\\partial w^{(l)}}=\\frac{\\partial E}{\\partial a^{(l)}}*\\frac{\\partial a^{(l)}}{\\partial z^{(l)}}*\\frac{ {\\partial z^{(l)}}}{\\partial w^{(l)}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924e57aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the derivative of an neuron output\n",
    "def transfer_derivative(output):\n",
    "\treturn output * (1.0 - output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1729353",
   "metadata": {},
   "source": [
    "## Erro Propagate Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841aca3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backpropagate error and store in neurons\n",
    "def backward_propagate_error(network, expected):\n",
    "\tfor i in reversed(range(len(network))):\n",
    "\t\tlayer = network[i]\n",
    "\t\terrors = list()\n",
    "\t\tif i != len(network)-1:\n",
    "\t\t\tfor j in range(len(layer)):\n",
    "\t\t\t\terror = 0.0\n",
    "\t\t\t\tfor neuron in network[i + 1]:\n",
    "\t\t\t\t\terror += (neuron['weights'][j] * neuron['delta'])\n",
    "\t\t\t\terrors.append(error)\n",
    "\t\telse:\n",
    "\t\t\tfor j in range(len(layer)):\n",
    "\t\t\t\tneuron = layer[j]\n",
    "\t\t\t\terrors.append(neuron['output'] - expected[j])\n",
    "\t\tfor j in range(len(layer)):\n",
    "\t\t\tneuron = layer[j]\n",
    "\t\t\tneuron['delta'] = errors[j] * transfer_derivative(neuron['output'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c27b6b72",
   "metadata": {},
   "source": [
    "# Train Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc79ea7",
   "metadata": {},
   "source": [
    "1. Update Weights.\n",
    "- $w^{(l)}_{+} = w^{(l)} - \\gamma * \\frac{\\partial E}{w^{(l)}} * input$. $\\gamma$ is learningrate \n",
    "2. Train Network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c98317",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update network weights with error\n",
    "def update_weights(network, row, l_rate):\n",
    "\tfor i in range(len(network)):\n",
    "\t\tinputs = row[:-1]\n",
    "\t\tif i != 0:\n",
    "\t\t\tinputs = [neuron['output'] for neuron in network[i - 1]]\n",
    "\t\tfor neuron in network[i]:\n",
    "\t\t\tfor j in range(len(inputs)):\n",
    "\t\t\t\tneuron['weights'][j] -= l_rate * neuron['delta'] * inputs[j]\n",
    "\t\t\tneuron['weights'][-1] -= l_rate * neuron['delta']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc655ef",
   "metadata": {},
   "source": [
    "## Train Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb3a603",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a network for a fixed number of epochs\n",
    "def train_network(network, train, l_rate, n_epoch, n_outputs):\n",
    "\tfor epoch in range(n_epoch):\n",
    "\t\tsum_error = 0\n",
    "\t\tfor row in train:\n",
    "\t\t\toutputs = forward_propagate(network, row)\n",
    "\t\t\texpected = [0 for i in range(n_outputs)]\n",
    "\t\t\texpected[row[-1]-1] = 1\n",
    "\t\t\tsum_error += sum([(expected[i]-outputs[i])**2 for i in range(len(expected))])\n",
    "\t\t\tbackward_propagate_error(network, expected)\n",
    "\t\t\tupdate_weights(network, row, l_rate)\n",
    "\t\tprint('>epoch=%d, lrate=%.3f, error=%.3f' % (epoch, l_rate, sum_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71f2c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inputs = len(dataset[0]) - 1\n",
    "n_outputs = len(set([row[-1] for row in dataset]))\n",
    "network = initialize_network(n_inputs, 18, n_outputs)\n",
    "train_network(network, dataset, 0.5, 100, n_outputs)\n",
    "for layer in network:\n",
    "\tprint(layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be44409",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47cb3821",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a prediction with a network\n",
    "def predict(network, row):\n",
    "\toutputs = forward_propagate(network, row)\n",
    "\treturn outputs.index(max(outputs))+1\n",
    "\n",
    "for row in dataset:\n",
    "    predicted=predict(network,row)\n",
    "    print(row,predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00cd1fe",
   "metadata": {},
   "source": [
    "# Applying for all pixel of image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf31a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "ouputdata=np.zeros((7911,7771)) #Data place to keep the classifed image data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa42b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "for r in range(7911):\n",
    "    #print(f'processing row {r}')\n",
    "    for c in range(7771):\n",
    "        predictOn=data[:,r,c].reshape(-1)\n",
    "        predictedValue=forward_propagate(network,predictOn)\n",
    "        classValue=predictedValue.index(max(predictedValue))+1\n",
    "        ouputdata[r,c]=classValue\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4fc81ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(ouputdata[2000:5050,6000:6050])\n",
    "#print(ouputdata[4000:5050,4000:5050])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1a34a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
